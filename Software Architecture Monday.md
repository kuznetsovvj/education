1. [**Request/Reply Pattern**](https://www.youtube.com/watch?v=3bxAm3XIFmk)

Используем две разных очереди сообщений для имитации request/reply. Сообщения можно связывать по CorrelationId (Id моего сообщения превращается в CorrelationId ответа) или через временные очереди (очереди только для одного соощения?).

2. [**Kafka vs Message Broker**](https://www.youtube.com/watch?v=lwMjjTT1Q-Q)

Kafka оптимизирована под постоянный поток простых сообщений key/value, с нагрузкой до 1M/s и только под паттерн Publisher/Subscriber.
RabbitMQ - транзакционные сообщение (может быть и большого размера), нагрузка до 10K/s с поддержкой трех разных паттернов (point-2-point, publisher-subscriber и exchange - роутинг одного сообщения по разным очередям)

3. [**Soft skills: Gaining Technical Breadth**](https://www.youtube.com/watch?v=vRplv975ce0)

Для архитектора важна не только глубина знаний ("знаю, что знаю"), но и ширина знаний ("знаю, что знаю + знаю, что не знаю"). Чтобы повышать ширину знаний, нужно больше читать о новых событиях в мире, например, InfoQueue, Technical Radar или DZone.

4. [**Microservices: Distributed Logging**](https://www.youtube.com/watch?v=S511BgBs_3E)

Микросервисы отличаются сложностью отладки, поэтому нужны хорошие логи. Выбрать инструмент для сбора логов (splunk, logstash, kafka и другие) - половина дела. Прием "консолидация логов" - объединение логов от разных микросервисов в один лог. Хорошо использовать "идентификатор контекста запроса" (если таких источников идентификаторов много - то здорово построить иерархию таких идентификаторов). Отличное место для извлечения id context - api gateway. Нужно поддерживать консистентность контекста - принимать его как входной параметр по всех запросах. Лучше сделать собственный wrapper для логов.





